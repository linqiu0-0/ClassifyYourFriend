{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWWp-l3Ahv1M"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSiSshM4Owtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# resturcture the train_data folder \n",
        "\n"
      ],
      "metadata": {
        "id": "bKLXYMczOxdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# # Set the path to the original folder\n",
        "# orig_path = '/content/drive/Shareddrives/cse 455/cat_dog_train_data'\n",
        "\n",
        "# # Set the path to the new folder structure\n",
        "# new_path = '/content/drive/Shareddrives/cse 455/dog_cat_data_restructured'\n",
        "\n",
        "# # Create the train, validation, and test folders\n",
        "# os.makedirs(os.path.join(new_path, 'train', 'cat'))\n",
        "# os.makedirs(os.path.join(new_path, 'train', 'dog'))\n",
        "# os.makedirs(os.path.join(new_path, 'validation', 'cat'))\n",
        "# os.makedirs(os.path.join(new_path, 'validation', 'dog'))\n",
        "# os.makedirs(os.path.join(new_path, 'test', 'cat'))\n",
        "# os.makedirs(os.path.join(new_path, 'test', 'dog'))\n",
        "\n",
        "# # Get the list of files in the original cat and dog folders\n",
        "# cat_files = os.listdir(os.path.join(orig_path, 'cat'))\n",
        "# dog_files = os.listdir(os.path.join(orig_path, 'dog'))\n",
        "\n",
        "# # Copy the first 1000 cat and dog files to the validation folder\n",
        "# for i in range(1000):\n",
        "#     shutil.copy(os.path.join(orig_path, 'cat', cat_files[i]), os.path.join(new_path, 'validation', 'cat'))\n",
        "#     shutil.copy(os.path.join(orig_path, 'dog', dog_files[i]), os.path.join(new_path, 'validation', 'dog'))\n",
        "\n",
        "# # Copy the last 1000 cat and dog files to the test folder\n",
        "# for i in range(-1000, 0):\n",
        "#     shutil.copy(os.path.join(orig_path, 'cat', cat_files[i]), os.path.join(new_path, 'test', 'cat'))\n",
        "#     shutil.copy(os.path.join(orig_path, 'dog', dog_files[i]), os.path.join(new_path, 'test', 'dog'))\n",
        "\n",
        "# # Copy the remaining files to the train folder\n",
        "# for file in cat_files[1000:] + dog_files[1000:]:\n",
        "#     if file in cat_files:\n",
        "#         shutil.copy(os.path.join(orig_path, 'cat', file), os.path.join(new_path, 'train', 'cat'))\n",
        "#     else:\n",
        "#         shutil.copy(os.path.join(orig_path, 'dog', file), os.path.join(new_path, 'train', 'dog'))\n"
      ],
      "metadata": {
        "id": "5-ohNWdWM-Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train "
      ],
      "metadata": {
        "id": "wWaECdZtO1dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0rBEhdk0lU-"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n",
        "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
        "import torch.nn.functional as F # All functions that don't have any parameters\n",
        "from torch.utils.data import DataLoader, Dataset # Gives easier dataset managment and creates mini batches\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCxoOmL0402"
      },
      "source": [
        "Set Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2vGYjxf01wY"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txpA2bhRKLiY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTFLBi_DrYax",
        "outputId": "f909ff31-9928-428c-b9b5-6b51bcc4b9a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "Yf38IYbNO647"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBsbencWhvH6"
      },
      "outputs": [],
      "source": [
        "FAST_RUN = False\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "DATA_PATH = \"/content/drive/Shareddrives/cse 455/dog_cat_data_restructured/\"\n",
        "BATCH_SIZE=16\n",
        "SAVE_TO = \"/content/drive/Shareddrives/cse 455/CatDogClassifer_models/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVawGk9YjigN"
      },
      "outputs": [],
      "source": [
        "## add data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "transforms.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n",
        "transforms.RandomCrop(IMAGE_WIDTH, padding=8, padding_mode='edge'), # Take IMAGE_WIDTHxIMAGE_WIDTH crops from padded images\n",
        "transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "transforms.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf \"/content/drive/Shareddrives/cse 455/dog_cat_data_restructured/validation/.ipynb_checkpoints\""
      ],
      "metadata": {
        "id": "65J-PN9rwJrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVkKpqpPhvlz"
      },
      "outputs": [],
      "source": [
        "data_train = datasets.ImageFolder(DATA_PATH + \"train\", transform=transform_train)\n",
        "data_test = datasets.ImageFolder(DATA_PATH + \"test\", transform=transform_test)\n",
        "data_val = datasets.ImageFolder(DATA_PATH + \"validation\", transform=transform_test)\n",
        "\n",
        "# dataset_subset = torch.utils.data.Subset(data, np.random.choice(len(data), 3000, replace=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeJD6lajjLdt",
        "outputId": "fe02c6ae-3954-4d1a-9327-97e1c57520d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2001"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(data_train)\n",
        "len(data_test)\n",
        "len(data_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD0uHEz6lwRA"
      },
      "outputs": [],
      "source": [
        "# train_size = int(0.8 * len(data))\n",
        "# test_size = int(0.1 * len(data))\n",
        "# val_size = len(data) - train_size - test_size\n",
        "\n",
        "# # train_size = 2500\n",
        "# # test_size = 250\n",
        "# # val_size = 250\n",
        "# train_size, val_size, test_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lseqKmq6on3v"
      },
      "outputs": [],
      "source": [
        "# train_set, val_set, test_set = torch.utils.data.random_split(data, [train_size, val_size, test_size])\n",
        "# train_set, val_set, test_set = torch.utils.data.random_split(dataset_subset, [train_size, val_size, test_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(dict(Counter(data_train.targets)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8PV2ay0EXBY",
        "outputId": "3640682a-58b8-4a56-cc39-cc43bcfee2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 29, 1: 11175, 2: 11500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OSy4-IFotS1"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "data_train,\n",
        "batch_size=BATCH_SIZE,\n",
        "shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "data_val,\n",
        "batch_size=BATCH_SIZE,\n",
        "shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "data_test,\n",
        "batch_size=BATCH_SIZE,\n",
        "shuffle=False\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "j3FYtLGFSud-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joWR8wzMpTLp"
      },
      "outputs": [],
      "source": [
        "class CatDogCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1) # size 112\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)  # size \n",
        "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
        "\n",
        "\n",
        "        # batch nomarlization layers \n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # conected layers\n",
        "        # 64 * 6 * 6 = 2304 neurons\n",
        "        self.fc1 = nn.Linear(in_features= 2304, out_features=500)\n",
        "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
        "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # flatten\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgM4m8lPrm7-"
      },
      "outputs": [],
      "source": [
        "class Darknet64DogCat(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Darknet64DogCat, self).__init__() # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2)\n",
        "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), kernel_size=2, stride=2)\n",
        "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), kernel_size=2, stride=2)\n",
        "        x = F.max_pool2d(F.relu(self.bn4(self.conv4(x))), kernel_size=2, stride=2)\n",
        "        x = F.max_pool2d(F.relu(self.bn5(self.conv5(x))), kernel_size=2, stride=2)\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKfZkpSPrspV"
      },
      "outputs": [],
      "source": [
        "model = CatDogCNN().to(DEVICE)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWGJ_i1rq1oM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "# add L2 regularization with weight decay\n",
        "def train(model = model, train_loader = train_loader, val_loader = val_loader, \n",
        "          epochs=EPOCHS, lr=0.001, schedule={}, decay=0.0005):\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  train_losses = []\n",
        "  train_accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
        "\n",
        "\n",
        "  for e in range(EPOCHS):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "\n",
        "\n",
        "     # Update learning rate when scheduled\n",
        "    if e in schedule:\n",
        "      print (\"Learning rate: %f\"% schedule[e])\n",
        "      for g in optimizer.param_groups:\n",
        "        g['lr'] = schedule[e]\n",
        "\n",
        "\n",
        "    loop = tqdm(enumerate(train_loader), total = len(train_loader))\n",
        "    # train model\n",
        "    for batch_idx, (x_batch, labels) in loop:\n",
        "      x_batch, labels = x_batch.to(DEVICE), labels.to(DEVICE)\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "       # forward + backward + optimize \n",
        "      labels_pred = model(x_batch)\n",
        "      batch_loss = loss(labels_pred, labels)\n",
        "      train_loss = train_loss + batch_loss.item()\n",
        "      labels_pred_max = torch.argmax(labels_pred, 1)\n",
        "      batch_acc = torch.sum(labels_pred_max == labels)\n",
        "      train_acc = train_acc + batch_acc.item()\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # update tqdm\n",
        "      loop.set_postfix(batch_idx= batch_idx, batch_acc= batch_acc.item() /BATCH_SIZE, loss= batch_loss.item())\n",
        "\n",
        "    # Validation loop; use .no_grad() context manager to save memory.\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "    train_accuracies.append(train_acc / (BATCH_SIZE * len(train_loader)))\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "      for (v_batch, labels) in val_loader:\n",
        "          v_batch, labels = v_batch.to(DEVICE), labels.to(DEVICE)\n",
        "          labels_pred = model(v_batch)\n",
        "          v_batch_loss = loss(labels_pred, labels)\n",
        "          val_loss = val_loss + v_batch_loss.item()\n",
        "\n",
        "          v_pred_max = torch.argmax(labels_pred, 1)\n",
        "          batch_acc = torch.sum(v_pred_max == labels)\n",
        "          val_acc = val_acc + batch_acc.item()\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_accuracies.append(val_acc / (BATCH_SIZE * len(val_loader)))\n",
        "    print(\"Epoch: {}, val loss: {:.4f}, val acc: {:.4f}, train loss: {:.4f}, train acc: {:.4f},\\n\".format(e, val_losses[e], val_accuracies[e], train_losses[e], train_accuracies[e]))\n",
        "    torch.save(model.state_dict(), SAVE_TO+\"DogCat_ckpt\" +  str(e)+ \".pt\")\n",
        "\n",
        "\n",
        "\n",
        "train(epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2mNXF5NrhnD"
      },
      "outputs": [],
      "source": [
        "# def evaluate(model: nn.Module, loader: DataLoader) :\n",
        "#   loss = nn.CrossEntropyLoss()\n",
        "#   model.eval()\n",
        "#   test_loss = 0.0\n",
        "#   test_acc = 0.0\n",
        "#   with torch.no_grad():\n",
        "#     for (batch, labels) in tqdm(loader):\n",
        "#       batch, labels = batch.to(DEVICE), labels.to(DEVICE)\n",
        "#       y_batch_pred = model(batch)\n",
        "#       batch_loss = loss(y_batch_pred, labels)\n",
        "#       test_loss = test_loss + batch_loss.item()\n",
        "\n",
        "#       pred_max = torch.argmax(y_batch_pred, 1)\n",
        "#       batch_acc = torch.sum(pred_max == labels)\n",
        "#       test_acc = test_acc + batch_acc.item()\n",
        "#     test_loss = test_loss / len(loader)\n",
        "#     test_acc = test_acc / (BATCH_SIZE * len(loader))\n",
        "#     return test_loss, test_acc\n",
        "\n",
        "def evaluate(model:  nn.Module, dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for  (batch, labels) in tqdm(dataloader):\n",
        "          images, labels = batch.to(DEVICE), labels.to(DEVICE)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, dim = 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_zJ8dSCeb67"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/Shareddrives/cse 455/CatDogClassifer_models/DogCat_ckpt9.pt'))\n",
        "\n",
        "test_acc = evaluate(model, test_loader)\n",
        "print(f\"\\n Test Accuracy: {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}