{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "sWWp-l3Ahv1M",
    "executionInfo": {
     "status": "error",
     "timestamp": 1678484893496,
     "user_tz": 480,
     "elapsed": 64015,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    },
    "outputId": "b4a37594-d719-41f1-ef51-b5d5d224be0b"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "B0rBEhdk0lU-",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893497,
     "user_tz": 480,
     "elapsed": 2,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader, Dataset # Gives easier dataset managment and creates mini batches\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set Device"
   ],
   "metadata": {
    "id": "SSCxoOmL0402"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu\n",
    "\n",
    "assert torch.backends.mps.is_available(), \"GPU is not available, check the directions above (or disable this assertion to use CPU)\"\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # use gpu or cpu"
   ],
   "metadata": {
    "id": "i2vGYjxf01wY",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893497,
     "user_tz": 480,
     "elapsed": 2,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE"
   ],
   "metadata": {
    "id": "PTFLBi_DrYax",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893498,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "#DATA_PATH = \"/content/drive/Shareddrives/cse 455/train_data\"\n",
    "DATA_PATH = \"Cat_Dog_train_data/\"\n",
    "BATCH_SIZE=100\n",
    "SAVE_TO = \"Saved\"\n"
   ],
   "metadata": {
    "id": "uBsbencWhvH6",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893498,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "transforms.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225))\n",
    "])\n"
   ],
   "metadata": {
    "id": "kVawGk9YjigN",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893498,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = datasets.ImageFolder(DATA_PATH, transform=transform)"
   ],
   "metadata": {
    "id": "bVkKpqpPhvlz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893498,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 46,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_six'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cse446/lib/python3.10/site-packages/torchvision/datasets/folder.py:310\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    304\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m ):\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cse446/lib/python3.10/site-packages/torchvision/datasets/folder.py:144\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    137\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    142\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    143\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfind_classes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot)\n\u001B[1;32m    146\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, class_to_idx, extensions, is_valid_file)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cse446/lib/python3.10/site-packages/torchvision/datasets/vision.py:39\u001B[0m, in \u001B[0;36mVisionDataset.__init__\u001B[0;34m(self, root, transforms, transform, target_transform)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     33\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     target_transform: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m     _log_api_usage_once(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(root, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_six\u001B[49m\u001B[38;5;241m.\u001B[39mstring_classes):\n\u001B[1;32m     40\u001B[0m         root \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(root)\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot \u001B[38;5;241m=\u001B[39m root\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute '_six'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data[1]"
   ],
   "metadata": {
    "id": "XeJD6lajjLdt",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893498,
     "user_tz": 480,
     "elapsed": 3,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_size = int(0.4 * len(data))\n",
    "test_size = int(0.1 * len(data))\n",
    "val_size = len(data) - train_size - test_size"
   ],
   "metadata": {
    "id": "uD0uHEz6lwRA",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0.4\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mdata\u001B[49m))\n\u001B[1;32m      2\u001B[0m test_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0.1\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(data))\n\u001B[1;32m      3\u001B[0m val_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m-\u001B[39m train_size \u001B[38;5;241m-\u001B[39m test_size\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_size, val_size, test_size"
   ],
   "metadata": {
    "id": "axaJH_wdoVm7",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(data, [train_size, val_size, test_size])"
   ],
   "metadata": {
    "id": "lseqKmq6on3v",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "train_set,\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "val_set,\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "test_set,\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True\n",
    ")"
   ],
   "metadata": {
    "id": "7OSy4-IFotS1",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CatDogCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        # conected layers\n",
    "        self.fc1 = nn.Linear(in_features= 2304, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x "
   ],
   "metadata": {
    "id": "joWR8wzMpTLp",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = CatDogCNN().to(DEVICE)"
   ],
   "metadata": {
    "id": "FgM4m8lPrm7-",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893499,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "metadata": {
    "id": "KKfZkpSPrspV",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), 0.0015)\n"
   ],
   "metadata": {
    "id": "0jGa6Ei8uNR5",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# online source\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ],
   "metadata": {
    "id": "IPx2PZgj7zO6",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    EPOCHS = 1\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    # print_every = 100\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "\n",
    "      model.train()\n",
    "      train_loss = 0.0\n",
    "      train_acc = 0.0\n",
    "\n",
    "      # itr = 0\n",
    "      # start = time.time()\n",
    "\n",
    "      for (x_batch, labels) in train_loader:\n",
    "        x_batch, labels = x_batch.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        labels_pred = model(x_batch)\n",
    "        batch_loss = loss(labels_pred, labels)\n",
    "        train_loss = train_loss + batch_loss.item()\n",
    "\n",
    "        labels_pred_max = torch.argmax(labels_pred, 1)\n",
    "        batch_acc = torch.sum(labels_pred_max == labels)\n",
    "        train_acc = train_acc + batch_acc.item()\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(train_acc / (BATCH_SIZE * len(train_loader)))\n",
    "\n",
    "\n",
    "        # itr = itr + 1\n",
    "        # if iter % print_every == 0:\n",
    "        #       print_loss_avg = train_loss / print_every\n",
    "        #       print('%s (%d %d%%) %.4f' % (timeSince(start, iter / len(train_loader)),\n",
    "        #                                     iter, iter / len(train_loader) * 100, print_loss_avg))\n",
    "        # Validation loop; use .no_grad() context manager to save memory.\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "          for (v_batch, labels) in val_loader:\n",
    "              v_batch, labels = v_batch.to(DEVICE), labels.to(DEVICE)\n",
    "              labels_pred = model(v_batch)\n",
    "              v_batch_loss = loss(labels_pred, labels)\n",
    "              val_loss = val_loss + v_batch_loss.item()\n",
    "\n",
    "              v_pred_max = torch.argmax(labels_pred, 1)\n",
    "              batch_acc = torch.sum(v_pred_max == labels)\n",
    "              val_acc = val_acc + batch_acc.item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_acc / (BATCH_SIZE * len(val_loader)))\n",
    "      print(\"Epoch: {}, val loss: {:.4f}, val acc: {:.4f}, train loss: {:.4f}, train acc: {:.4f},\\n\".format(e, val_losses[e], val_accuracies[e], train_losses[e], train_accuracies[e]))\n"
   ],
   "metadata": {
    "id": "GWGJ_i1rq1oM",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CatDogCNN.train()\n",
    "torch.save(CatDogCNN.state_dict(), SAVE_TO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader) :\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  model.eval()\n",
    "  test_loss = 0.0\n",
    "  test_acc = 0.0\n",
    "  with torch.no_grad():\n",
    "    for (batch, labels) in loader:\n",
    "      batch, labels = batch.to(DEVICE), labels.to(DEVICE)\n",
    "      y_batch_pred = model(batch)\n",
    "      batch_loss = loss(y_batch_pred, labels)\n",
    "      test_loss = test_loss + batch_loss.item()\n",
    "\n",
    "      pred_max = torch.argmax(y_batch_pred, 1)\n",
    "      batch_acc = torch.sum(pred_max == labels)\n",
    "      test_acc = test_acc + batch_acc.item()\n",
    "    test_loss = test_loss / len(loader)\n",
    "    test_acc = test_acc / (BATCH_SIZE * len(loader))\n",
    "    return test_loss, test_acc"
   ],
   "metadata": {
    "id": "L2mNXF5NrhnD",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ],
   "metadata": {
    "id": "q_zJ8dSCeb67",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1678484893500,
     "user_tz": 480,
     "elapsed": 4,
     "user": {
      "displayName": "Wenxin Zhang",
      "userId": "08924261935319325962"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}