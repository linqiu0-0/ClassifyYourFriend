{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'Afghan',\n 1: 'African Wild Dog',\n 2: 'Airedale',\n 3: 'American Hairless',\n 4: 'American Spaniel',\n 5: 'Basenji',\n 6: 'Basset',\n 7: 'Beagle',\n 8: 'Bearded Collie',\n 9: 'Bermaise',\n 10: 'Bichon Frise',\n 11: 'Blenheim',\n 12: 'Bloodhound',\n 13: 'Bluetick',\n 14: 'Border Collie',\n 15: 'Borzoi',\n 16: 'Boston Terrier',\n 17: 'Boxer',\n 18: 'Bull Mastiff',\n 19: 'Bull Terrier',\n 20: 'Bulldog',\n 21: 'Cairn',\n 22: 'Chihuahua',\n 23: 'Chinese Crested',\n 24: 'Chow',\n 25: 'Clumber',\n 26: 'Cockapoo',\n 27: 'Cocker',\n 28: 'Collie',\n 29: 'Corgi',\n 30: 'Coyote',\n 31: 'Dalmation',\n 32: 'Dhole',\n 33: 'Dingo',\n 34: 'Doberman',\n 35: 'Elk Hound',\n 36: 'French Bulldog',\n 37: 'German Sheperd',\n 38: 'Golden Retriever',\n 39: 'Great Dane',\n 40: 'Great Perenees',\n 41: 'Greyhound',\n 42: 'Groenendael',\n 43: 'Irish Spaniel',\n 44: 'Irish Wolfhound',\n 45: 'Japanese Spaniel',\n 46: 'Komondor',\n 47: 'Labradoodle',\n 48: 'Labrador',\n 49: 'Lhasa',\n 50: 'Malinois',\n 51: 'Maltese',\n 52: 'Mex Hairless',\n 53: 'Newfoundland',\n 54: 'Pekinese',\n 55: 'Pit Bull',\n 56: 'Pomeranian',\n 57: 'Poodle',\n 58: 'Pug',\n 59: 'Rhodesian',\n 60: 'Rottweiler',\n 61: 'Saint Bernard',\n 62: 'Schnauzer',\n 63: 'Scotch Terrier',\n 64: 'Shar_Pei',\n 65: 'Shiba Inu',\n 66: 'Shih-Tzu',\n 67: 'Siberian Husky',\n 68: 'Vizsla',\n 69: 'Yorkie'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# breeds = os.listdir(\"DogBreed/test\")\n",
    "# breeds = sorted(breeds)\n",
    "# breeds.pop(0)\n",
    "# breed_map = dict()\n",
    "#\n",
    "# for i in range(len(breeds)):\n",
    "#     breed_map[i] = breeds[i]\n",
    "# breed_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('DogBreedMap.csv', 'w') as f:\n",
    "#     w = csv.writer(f)\n",
    "#     w.writerows(breed_map.items())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader, Dataset  # Gives easier dataset managment and creates mini batches\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu\n",
    "\n",
    "assert torch.backends.mps.is_available(), \"GPU is not available, check the directions above (or disable this assertion to use CPU)\"\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")  # use gpu or cpu\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3\n",
    "# DATA_PATH = \"/content/drive/Shareddrives/cse 455/train_data\"\n",
    "DATA_PATH = \"DogBreed\"\n",
    "BATCH_SIZE = 100\n",
    "SAVE_TO = \"Saved\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data = datasets.ImageFolder(DATA_PATH, transform=transform)\n",
    "train_set = datasets.ImageFolder(DATA_PATH + \"/train\", transform=transform)\n",
    "val_set = datasets.ImageFolder(DATA_PATH + \"/valid\", transform=transform)\n",
    "test_set = datasets.ImageFolder(DATA_PATH + \"/test\", transform=transform)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "\n",
    "        # conected layers\n",
    "        self.fc1 = nn.Linear(in_features=2304, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = CatBreedCNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), 0.0015)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    EPOCHS = 1\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    # print_every = 100\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        # itr = 0\n",
    "        # start = time.time()\n",
    "\n",
    "        for (x_batch, labels) in train_loader:\n",
    "            x_batch, labels = x_batch.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            labels_pred = model(x_batch)\n",
    "            batch_loss = loss(labels_pred, labels)\n",
    "            train_loss = train_loss + batch_loss.item()\n",
    "\n",
    "            labels_pred_max = torch.argmax(labels_pred, 1)\n",
    "            batch_acc = torch.sum(labels_pred_max == labels)\n",
    "            train_acc = train_acc + batch_acc.item()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "            train_accuracies.append(train_acc / (BATCH_SIZE * len(train_loader)))\n",
    "\n",
    "            # itr = itr + 1\n",
    "            # if iter % print_every == 0:\n",
    "            #       print_loss_avg = train_loss / print_every\n",
    "            #       print('%s (%d %d%%) %.4f' % (timeSince(start, iter / len(train_loader)),\n",
    "            #                                     iter, iter / len(train_loader) * 100, print_loss_avg))\n",
    "            # Validation loop; use .no_grad() context manager to save memory.\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for (v_batch, labels) in val_loader:\n",
    "                    v_batch, labels = v_batch.to(DEVICE), labels.to(DEVICE)\n",
    "                    labels_pred = model(v_batch)\n",
    "                    v_batch_loss = loss(labels_pred, labels)\n",
    "                    val_loss = val_loss + v_batch_loss.item()\n",
    "\n",
    "                    v_pred_max = torch.argmax(labels_pred, 1)\n",
    "                    batch_acc = torch.sum(v_pred_max == labels)\n",
    "                    val_acc = val_acc + batch_acc.item()\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_acc / (BATCH_SIZE * len(val_loader)))\n",
    "        print(\"Epoch: {}, val loss: {:.4f}, val acc: {:.4f}, train loss: {:.4f}, train acc: {:.4f},\\n\".format(e,\n",
    "                val_losses[e],val_accuracies[e],train_losses[e],train_accuracies[e]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DogBreedCNN.train()\n",
    "torch.save(DogBreedCNN.state_dict(), SAVE_TO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (batch, labels) in loader:\n",
    "            batch, labels = batch.to(DEVICE), labels.to(DEVICE)\n",
    "            y_batch_pred = model(batch)\n",
    "            batch_loss = loss(y_batch_pred, labels)\n",
    "            test_loss = test_loss + batch_loss.item()\n",
    "\n",
    "            pred_max = torch.argmax(y_batch_pred, 1)\n",
    "            batch_acc = torch.sum(pred_max == labels)\n",
    "            test_acc = test_acc + batch_acc.item()\n",
    "        test_loss = test_loss / len(loader)\n",
    "        test_acc = test_acc / (BATCH_SIZE * len(loader))\n",
    "        return test_loss, test_acc\n",
    "\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}